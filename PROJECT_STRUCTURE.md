# Project Structure
```
izu-rag-chatbot/
â”œâ”€â”€ ğŸ“„ DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                     # Main documentation
â”‚   â”œâ”€â”€ SETUP.md                      # Setup instructions
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md          # Project structure description
â”‚   â””â”€â”€ ADVANCED_CRAWLER_README.md    # Crawler documentation
â”‚
â”œâ”€â”€ ğŸ¤– CHATBOT
â”‚   â”œâ”€â”€ chatbot_api.py                # FastAPI backend
â”‚   â”œâ”€â”€ chatbot_ui.html               # Web interface
â”‚   â”œâ”€â”€ start_chatbot.sh              # Quick start script
â”‚   â”œâ”€â”€ requirements_chatbot.txt      # FastAPI dependencies
â”‚   â””â”€â”€ .env                          # API keys (not in git)
â”‚
â”œâ”€â”€ ğŸ•·ï¸ DATA COLLECTION
â”‚   â”œâ”€â”€ advanced_izu_crawler.py        # Main crawler
â”‚   â”œâ”€â”€ crawler_utils.py               # Text processing utilities
â”‚   â”œâ”€â”€ extraction_strategies.py       # Content extractors
â”‚   â”œâ”€â”€ izu_data_models.py             # Data structures
â”‚   â”œâ”€â”€ example_usage.py               # Usage examples
â”‚   â”œâ”€â”€ requirements_advanced.txt      # Crawler dependencies
â”‚   â”‚
â”‚   â””â”€â”€ izu_scraper/                   # Legacy Scrapy project
â”‚       â”œâ”€â”€ settings.py
â”‚       â”œâ”€â”€ items.py
â”‚       â”œâ”€â”€ pipelines.py
â”‚       â””â”€â”€ spiders/
â”‚           â””â”€â”€ izu_spider.py           # Original spider
â”‚
â”œâ”€â”€ ğŸ”§ DATA PROCESSING
â”‚   â”œâ”€â”€ merge_crawler_data.py          # Merge old and new data
â”‚   â”œâ”€â”€ convert_for_chunking.py        # Format conversion
â”‚   â””â”€â”€ rechunk_with_merged_data.py    # Automated chunking
â”‚
â”œâ”€â”€ ğŸ“Š EVALUATION & EXPERIMENTS
â”‚   â”œâ”€â”€ data_preparation.py            # Prepare experiment data
â”‚   â”œâ”€â”€ phase2_experiments.py          # Test configurations
â”‚   â””â”€â”€ izu_rag_results_bge.csv        # Experiment results
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ RAG SYSTEM & CHUNKING
â”‚   â””â”€â”€ chunking/
â”‚       â”œâ”€â”€ chunks.json                # Processed chunks (1,154)
â”‚       â”œâ”€â”€ faiss_index.bin             # Vector index
â”‚       â”œâ”€â”€ embeddings_openai_izu.npy   # OpenAI embeddings (1536-dim)
â”‚       â”œâ”€â”€ test_dataset.json           # 50 evaluation questions
â”‚       â”œâ”€â”€ quick_test.py               # 5-question smoke test
â”‚       â”œâ”€â”€ evaluation.ipynb            # Full evaluation notebook
â”‚       â”œâ”€â”€ generate_evaluation_report.py
â”‚       â”œâ”€â”€ chunking.ipynb              # Original chunking notebook
â”‚       â”œâ”€â”€ rag_system.ipynb            # RAG system notebook
â”‚       â”œâ”€â”€ chat.py                     # Simple chat interface
â”‚       â”œâ”€â”€ interactive_chat.py         # Interactive chat
â”‚       â””â”€â”€ rag_config.json             # System configuration
â”‚
â”œâ”€â”€ ğŸ“¦ OUTPUT (not in git)
â”‚   â”œâ”€â”€ izu_advanced_data.json          # Advanced crawler output
â”‚   â”œâ”€â”€ izu_merged_data.json            # Merged data (573 pages)
â”‚   â””â”€â”€ data_exports/                   # Additional exports
â”‚
â”œâ”€â”€ ğŸ“ CONFIGURATION
â”‚   â”œâ”€â”€ requirements.txt               # Core dependencies
â”‚   â”œâ”€â”€ .gitignore                     # Git ignore rules
â”‚   â”œâ”€â”€ .env                           # Environment variables (not in git)
â”‚   â””â”€â”€ scrapy.cfg                     # Scrapy configuration
â”‚
â””â”€â”€ ğŸ”¨ UTILITIES
    â”œâ”€â”€ run_spider.sh                  # Run Scrapy spider
    â””â”€â”€ logs/                          # Application logs (not in git)

```

## Large Files (Not in Git - Generated)

These files are generated during setup and excluded via [.gitignore](cci:7://file:///home/zeynkash/projects/izu_scraper/.gitignore:0:0-0:0):

### Generated by Crawler:
- [output/izu_advanced_data.json](cci:7://file:///home/zeynkash/projects/izu_scraper/output/izu_advanced_data.json:0:0-0:0) (~2-5 MB)
- [output/izu_merged_data.json](cci:7://file:///home/zeynkash/projects/izu_scraper/output/izu_merged_data.json:0:0-0:0) (~2-5 MB)

### Generated by RAG System:
- [chunking/chunks.json](cci:7://file:///home/zeynkash/projects/izu_scraper/chunking/chunks.json:0:0-0:0) (~5-10 MB)
- [chunking/faiss_index.bin](cci:7://file:///home/zeynkash/projects/izu_scraper/chunking/faiss_index.bin:0:0-0:0) (~20-50 MB)
- [chunking/embeddings_openai_izu.npy](cci:7://file:///home/zeynkash/projects/izu_scraper/chunking/embeddings_openai_izu.npy:0:0-0:0) (~10-20 MB)

### Generated by Experiments:
- `izu_chunks*.pkl` (~2-4 MB each)
- `izu_embeddings*.npy` (~4-10 MB each)
- [izu_rag_results_bge.csv](cci:7://file:///home/zeynkash/projects/izu_scraper/izu_rag_results_bge.csv:0:0-0:0) (~4 KB)

## Key New Features

### 1. FastAPI Chatbot
- **Backend**: [chatbot_api.py](cci:7://file:///home/zeynkash/projects/izu_scraper/chatbot_api.py:0:0-0:0) - RESTful API
- **Frontend**: [chatbot_ui.html](cci:7://file:///home/zeynkash/projects/izu_scraper/chatbot_ui.html:0:0-0:0) - Modern web UI
- **Docs**: http://localhost:8000/docs
- **Performance**: 2.69s avg response, $0.0005/query

### 2. Advanced Crawler
- **Intelligent categorization** (10 types)
- **Structured extraction** (programs, faculty, fees)
- **Multi-language support** (TR/EN)
- **Smart deduplication**

### 3. Comprehensive Evaluation
- **50 test questions** with ground truth
- **Multiple metrics** (similarity, retrieval, performance)
- **Quick test** (5 questions, 2 mins)
- **Full evaluation** (50 questions, 15 mins)

## File Sizes Overview

| Component | Size | Status |
|-----------|------|--------|
| Code (Python, HTML, etc.) | ~500 KB | âœ… In Git |
| Documentation (MD files) | ~200 KB | âœ… In Git |
| Configuration | ~50 KB | âœ… In Git |
| Generated Data | ~50-100 MB | âŒ Not in Git |
| Evaluation Results | ~5-10 MB | âš ï¸ Selected in Git |

## Setup Instructions

See [SETUP.md](cci:7://file:///home/zeynkash/projects/izu_scraper/SETUP.md:0:0-0:0) for detailed installation and configuration instructions.

## Repository

**URL**: https://github.com/zeynkash/izu-rag-chatbot
**Status**: Production Ready âœ…
**Last Updated**: December 2025
